{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thainer-1-4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGFM46teSuuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3d23cb31-56bb-48e7-bf56-16532a0e1f8a"
      },
      "source": [
        "!wget https://github.com/wannaphong/thai-ner/raw/master/model/1.3/data.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-21 08:22:51--  https://github.com/wannaphong/thai-ner/raw/master/model/1.3/data.txt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/wannaphong/thai-ner/master/model/1.3/data.txt [following]\n",
            "--2020-05-21 08:22:52--  https://raw.githubusercontent.com/wannaphong/thai-ner/master/model/1.3/data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3393309 (3.2M) [text/plain]\n",
            "Saving to: ‘data.txt’\n",
            "\n",
            "data.txt            100%[===================>]   3.24M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-05-21 08:22:52 (57.8 MB/s) - ‘data.txt’ saved [3393309/3393309]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yspMGZpSwUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "70ea675f-f838-4cd1-ba7f-fc379f1e15ad"
      },
      "source": [
        "!pip install pythainlp python-crfsuite dill"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/14/b80930a2cc09ed6b5f8a22da9be6ece56939839ae66d921d9c7123034ba0/pythainlp-2.1.4-py3-none-any.whl (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 1.6MB/s \n",
            "\u001b[?25hCollecting python-crfsuite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (0.3.1.1)\n",
            "Collecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 38.7MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/f6/b3e112addc8eb4a097f158124ce8b206767361a381f80c5f0c506d855e4a/tinydb-4.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.1 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (0.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434676 sha256=49c6c75ab28107680572317970f1555ac3773a9813479e0eb11546862582f287\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk, tinydb, pythainlp, python-crfsuite\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5 pythainlp-2.1.4 python-crfsuite-0.9.7 tinydb-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2CTtujqS9bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name=\"data\"\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.tag import pos_tag\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import glob\n",
        "import nltk\n",
        "import re\n",
        "# thai cut\n",
        "thaicut=\"newmm\"\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_validate,train_test_split\n",
        "import pycrfsuite\n",
        "from pythainlp.corpus.common import thai_stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B7uegB8S96w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = list(thai_stopwords())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwo6b8UnTG7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#จัดการประโยคซ้ำ\n",
        "data_not=[]\n",
        "def Unique(p):\n",
        " text=re.sub(\"<[^>]*>\",\"\",p)\n",
        " text=re.sub(\"\\[(.*?)\\]\",\"\",text)\n",
        " text=re.sub(\"\\[\\/(.*?)\\]\",\"\",text)\n",
        " if text not in data_not:\n",
        "  data_not.append(text)\n",
        "  return True\n",
        " else:\n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDjvQRvATJLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# เตรียมตัวตัด tag ด้วย re\n",
        "pattern = r'\\[(.*?)\\](.*?)\\[\\/(.*?)\\]'\n",
        "tokenizer = RegexpTokenizer(pattern) # ใช้ nltk.tokenize.RegexpTokenizer เพื่อตัด [TIME]8.00[/TIME] ให้เป็น ('TIME','ไง','TIME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeL3nDIbTLME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# จัดการกับ tag ที่ไม่ได้ tag\n",
        "def toolner_to_tag(text):\n",
        " text=text.strip().replace(\"FACILITY\",\"LOCATION\").replace(\"[AGO]\",\"\").replace(\"[/AGO]\",\"\").replace(\"[T]\",\"\").replace(\"[/T]\",\"\")\n",
        " text=re.sub(\"<[^>]*>\",\"\",text)\n",
        " text=re.sub(\"(\\[\\/(.*?)\\])\",\"\\\\1***\",text)#.replace('(\\[(.*?)\\])','***\\\\1')# text.replace('>','>***') # ตัดการกับพวกไม่มี tag word\n",
        " text=re.sub(\"(\\[\\w+\\])\",\"***\\\\1\",text)\n",
        " text2=[]\n",
        " for i in text.split('***'):\n",
        "  if \"[\" in i:\n",
        "   text2.append(i)\n",
        "  else:\n",
        "   text2.append(\"[word]\"+i+\"[/word]\")\n",
        " text=\"\".join(text2)#re.sub(\"[word][/word]\",\"\",\"\".join(text2))\n",
        " return text.replace(\"[word][/word]\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjz27FYbTNBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# แปลง text ให้เป็น conll2002\n",
        "def text2conll2002(text,pos=True):\n",
        "    \"\"\"\n",
        "    ใช้แปลงข้อความให้กลายเป็น conll2002\n",
        "    \"\"\"\n",
        "    text=toolner_to_tag(text)\n",
        "    text=text.replace(\"''\",'\"')\n",
        "    text=text.replace(\"’\",'\"').replace(\"‘\",'\"')#.replace('\"',\"\")\n",
        "    tag=tokenizer.tokenize(text)\n",
        "    j=0\n",
        "    conll2002=\"\"\n",
        "    for tagopen,text,tagclose in tag:\n",
        "        word_cut=word_tokenize(text,engine=thaicut) # ใช้ตัวตัดคำ newmm\n",
        "        i=0\n",
        "        txt5=\"\"\n",
        "        while i<len(word_cut):\n",
        "            if word_cut[i]==\"''\" or word_cut[i]=='\"':pass\n",
        "            elif i==0 and tagopen!='word':\n",
        "                txt5+=word_cut[i]\n",
        "                txt5+='\\t'+'B-'+tagopen\n",
        "            elif tagopen!='word':\n",
        "                txt5+=word_cut[i]\n",
        "                txt5+='\\t'+'I-'+tagopen\n",
        "            else:\n",
        "                txt5+=word_cut[i]\n",
        "                txt5+='\\t'+'O'\n",
        "            txt5+='\\n'\n",
        "            #j+=1\n",
        "            i+=1\n",
        "        conll2002+=txt5\n",
        "    if pos==False:\n",
        "        return conll2002\n",
        "    return postag(conll2002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyepM-qqTQwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ใช้สำหรับกำกับ pos tag เพื่อใช้กับ NER\n",
        "def postag(text):\n",
        "    listtxt=[i for i in text.split('\\n') if i!='']\n",
        "    list_word=[]\n",
        "    for data in listtxt:\n",
        "        list_word.append(data.split('\\t')[0])\n",
        "    #print(text)\n",
        "    list_word=pos_tag(list_word,engine=\"perceptron\", corpus=\"orchid_ud\")\n",
        "    text=\"\"\n",
        "    i=0\n",
        "    for data in listtxt:\n",
        "        text+=data.split('\\t')[0]+'\\t'+list_word[i][1]+'\\t'+data.split('\\t')[1]+'\\n'\n",
        "        i+=1\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsfHU4ltTUJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# เขียนไฟล์ข้อมูล conll2002\n",
        "def write_conll2002(file_name,data):\n",
        "    \"\"\"\n",
        "    ใช้สำหรับเขียนไฟล์\n",
        "    \"\"\"\n",
        "    with codecs.open(file_name, \"w\", \"utf-8-sig\") as temp:\n",
        "        temp.write(data)\n",
        "    return True\n",
        "# อ่านข้อมูลจากไฟล์\n",
        "def get_data(fileopen):\n",
        "\t\"\"\"\n",
        "    สำหรับใช้อ่านทั้งหมดทั้งในไฟล์ทีละรรทัดออกมาเป็น list\n",
        "    \"\"\"\n",
        "\twith codecs.open(fileopen, 'r',encoding='utf-8-sig') as f:\n",
        "\t\tlines = f.read().splitlines()\n",
        "\treturn [a for a in tqdm(lines) if Unique(a)] # เอาไม่ซ้ำกัน"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yES8h0pATXrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def alldata(lists):\n",
        "    text=\"\"\n",
        "    for data in lists:\n",
        "        text+=text2conll2002(data)\n",
        "        text+='\\n'\n",
        "    return text\n",
        "\n",
        "def alldata_list(lists):\n",
        "    data_all=[]\n",
        "    for data in lists:\n",
        "        data_num=[]\n",
        "        try:\n",
        "            txt=text2conll2002(data,pos=True).split('\\n')\n",
        "            for d in txt:\n",
        "                tt=d.split('\\t')\n",
        "                if d!=\"\":\n",
        "                    if len(tt)==3:\n",
        "                        data_num.append((tt[0],tt[1],tt[2]))\n",
        "                    else:\n",
        "                        data_num.append((tt[0],tt[1]))\n",
        "            #print(data_num)\n",
        "            data_all.append(data_num)\n",
        "        except:\n",
        "            print(data)\n",
        "    #print(data_all)\n",
        "    return data_all\n",
        "\n",
        "def alldata_list_str(lists):\n",
        "\tstring=\"\"\n",
        "\tfor data in lists:\n",
        "\t\tstring1=\"\"\n",
        "\t\tfor j in data:\n",
        "\t\t\tstring1+=j[0]+\"\t\"+j[1]+\"\t\"+j[2]+\"\\n\"\n",
        "\t\tstring1+=\"\\n\"\n",
        "\t\tstring+=string1\n",
        "\treturn string\n",
        "\n",
        "def get_data_tag(listd):\n",
        "\tlist_all=[]\n",
        "\tc=[]\n",
        "\tfor i in listd:\n",
        "\t\tif i !='':\n",
        "\t\t\tc.append((i.split(\"\\t\")[0],i.split(\"\\t\")[1],i.split(\"\\t\")[2]))\n",
        "\t\telse:\n",
        "\t\t\tlist_all.append(c)\n",
        "\t\t\tc=[]\n",
        "\treturn list_all\n",
        "def getall(lista):\n",
        "    ll=[]\n",
        "    for i in tqdm(lista):\n",
        "        o=True\n",
        "        for j in ll:\n",
        "            if re.sub(\"\\[(.*?)\\]\",\"\",i)==re.sub(\"\\[(.*?)\\]\",\"\",j):\n",
        "                o=False\n",
        "                break\n",
        "        if o==True:\n",
        "            ll.append(i)\n",
        "    return ll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xo-lGsJTdRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e76175a7-8ff9-46bc-ccad-1c9e7b6ee6e7"
      },
      "source": [
        "'''data1=getall(get_data(file_name+\".txt\"))\n",
        "print(len(data1))\n",
        "\n",
        "\n",
        "#del datatofile[0]\n",
        "datatofile=alldata_list(data1)\n",
        "tt=[]\n",
        "#datatofile.reverse()\n",
        "import random\n",
        "#random.shuffle(datatofile)\n",
        "print(len(datatofile))\n",
        "#training_samples = datatofile[:int(len(datatofile) * 0.8)]\n",
        "#test_samples = datatofile[int(len(datatofile) * 0.8):]'''\n",
        "'''training_samples = datatofile[:2822]\n",
        "test_samples = datatofile[2822:]'''\n",
        "#print(test_samples[0])\n",
        "#tag=TrainChunker(training_samples,test_samples) # Train\n",
        "\n",
        "#run(training_samples,test_samples)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_samples = datatofile[:2822]\\ntest_samples = datatofile[2822:]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmf4063KTlz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2f52d9f9-97dc-4866-d00d-250e9f5614bc"
      },
      "source": [
        "!wget https://github.com/wannaphong/thai-ner/raw/master/model/1.3/train.data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-21 08:23:13--  https://github.com/wannaphong/thai-ner/raw/master/model/1.3/train.data\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/wannaphong/thai-ner/master/model/1.3/train.data [following]\n",
            "--2020-05-21 08:23:13--  https://raw.githubusercontent.com/wannaphong/thai-ner/master/model/1.3/train.data\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11598502 (11M) [application/octet-stream]\n",
            "Saving to: ‘train.data’\n",
            "\n",
            "\rtrain.data            0%[                    ]       0  --.-KB/s               \rtrain.data           71%[=============>      ]   7.92M  39.6MB/s               \rtrain.data          100%[===================>]  11.06M  46.4MB/s    in 0.2s    \n",
            "\n",
            "2020-05-21 08:23:14 (46.4 MB/s) - ‘train.data’ saved [11598502/11598502]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjBiB1AtTk2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill\n",
        "with open('train.data', 'rb') as file:\n",
        " datatofile = dill.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot1JbKAZTw6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(file_name+\"-pos.conll\",\"w\") as f:\n",
        "    i=0\n",
        "    while i<len(datatofile):\n",
        "        for j in datatofile[i]:\n",
        "            f.write(j[0]+\"\\t\"+j[1]+\"\\t\"+j[2]+\"\\n\")\n",
        "        if i+1<len(datatofile):\n",
        "            f.write(\"\\n\")\n",
        "        i+=1\n",
        "\n",
        "with open(file_name+\".conll\",\"w\") as f:\n",
        "    i=0\n",
        "    while i<len(datatofile):\n",
        "        for j in datatofile[i]:\n",
        "            f.write(j[0]+\"\\t\"+j[2]+\"\\n\")\n",
        "        if i+1<len(datatofile):\n",
        "            f.write(\"\\n\")\n",
        "        i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjzG3gK6T2fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isThai(chr):\n",
        " cVal = ord(chr)\n",
        " if(cVal >= 3584 and cVal <= 3711):\n",
        "  return True\n",
        " return False\n",
        "def isThaiWord(word):\n",
        " t=True\n",
        " for i in word:\n",
        "  l=isThai(i)\n",
        "  if l!=True and i!='.':\n",
        "   t=False\n",
        "   break\n",
        " return t\n",
        "\n",
        "def is_stopword(word):\n",
        "    return word in stopwords\n",
        "def is_s(word):\n",
        "    if word == \" \" or word ==\"\\t\" or word==\"\":\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def lennum(word,num):\n",
        "    if len(word)==num:\n",
        "        return True\n",
        "    return False\n",
        "def doc2features(doc, i):\n",
        "    word = doc[i][0]\n",
        "    postag = doc[i][1]\n",
        "    # Features from current word\n",
        "    features={\n",
        "        'word.word': word,\n",
        "        'word.stopword': is_stopword(word),\n",
        "        'word.isthai':isThaiWord(word),\n",
        "        'word.isspace':word.isspace(),\n",
        "        'postag':postag,\n",
        "        'word.isdigit()': word.isdigit()\n",
        "    }\n",
        "    if word.isdigit() and len(word)==5:\n",
        "        features['word.islen5']=True\n",
        "    if i > 0:\n",
        "        prevword = doc[i-1][0]\n",
        "        postag1 = doc[i-1][1]\n",
        "        features['word.prevword'] = prevword\n",
        "        features['word.previsspace']=prevword.isspace()\n",
        "        features['word.previsthai']=isThaiWord(prevword)\n",
        "        features['word.prevstopword']=is_stopword(prevword)\n",
        "        features['word.prepostag'] = postag1\n",
        "        features['word.prevwordisdigit'] = prevword.isdigit()\n",
        "    else:\n",
        "        features['BOS'] = True # Special \"Beginning of Sequence\" tag\n",
        "    # Features from next word\n",
        "    if i < len(doc)-1:\n",
        "        nextword = doc[i+1][0]\n",
        "        postag1 = doc[i+1][1]\n",
        "        features['word.nextword'] = nextword\n",
        "        features['word.nextisspace']=nextword.isspace()\n",
        "        features['word.nextpostag'] = postag1\n",
        "        features['word.nextisthai']=isThaiWord(nextword)\n",
        "        features['word.nextstopword']=is_stopword(nextword)\n",
        "        features['word.nextwordisdigit'] = nextword.isdigit()\n",
        "    else:\n",
        "        features['EOS'] = True # Special \"End of Sequence\" tag\n",
        "    return features\n",
        "\n",
        "def extract_features(doc):\n",
        "    return [doc2features(doc, i) for i in range(len(doc))]\n",
        "\n",
        "def get_labels(doc):\n",
        "    return [tag for (token,postag,tag) in doc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvo1BpSvT5cB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "444c7240-118f-40ea-eded-7e582102281d"
      },
      "source": [
        "X_data = [extract_features(doc) for doc in tqdm(datatofile)]\n",
        "y_data = [get_labels(doc) for doc in tqdm(datatofile)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6349/6349 [00:09<00:00, 699.20it/s]\n",
            "100%|██████████| 6349/6349 [00:00<00:00, 240870.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BmBi5-6T7IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7Kfz_KFaMwA",
        "colab_type": "text"
      },
      "source": [
        "## Train TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ylytGGUE9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1f4a5734-1f73-4372-ffd7-d3c98543c429"
      },
      "source": [
        "%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X, y):\n",
        "    try:\n",
        "      trainer.append(xseq, yseq)\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.56 s, sys: 39.7 ms, total: 2.6 s\n",
            "Wall time: 2.61 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boCF-Gp8UI2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.set_params({\n",
        "    'c1': 0.1,   # coefficient for L1 penalty\n",
        "    'c2': 0.1,  # coefficient for L2 penalty\n",
        "    'max_iterations': 500,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYSkO1QKUVyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "01bc5e12-36a0-48e4-e6b9-b5c5d8eb6760"
      },
      "source": [
        "trainer.params()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feature.minfreq',\n",
              " 'feature.possible_states',\n",
              " 'feature.possible_transitions',\n",
              " 'c1',\n",
              " 'c2',\n",
              " 'max_iterations',\n",
              " 'num_memories',\n",
              " 'epsilon',\n",
              " 'period',\n",
              " 'delta',\n",
              " 'linesearch',\n",
              " 'max_linesearch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqosgzLgUauo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1658c895-a74b-4820-8bd7-ce5d453fbe7b"
      },
      "source": [
        "%%time\n",
        "trainer.train('thai-ner-1-4-test.crfsuite')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 21s, sys: 500 ms, total: 9min 21s\n",
            "Wall time: 9min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D67qfUnUtn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import chain\n",
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Classification report for a list of BIO-encoded sequences.\n",
        "    It computes token-level metrics and discards \"O\" labels.\n",
        "    \n",
        "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
        "    to calculate averages properly!\n",
        "    \"\"\"\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "        \n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn_OKTdUUyi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1106e2ca-8e61-4dfa-a2e2-88bb7dca8188"
      },
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('thai-ner-1-4-test.crfsuite')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7fa0370e0668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKKp55vJUvqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "07a486f8-cb74-4857-b9c8-02075c67ed6b"
      },
      "source": [
        "%%time\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 799 ms, sys: 2.01 ms, total: 801 ms\n",
            "Wall time: 806 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHOROL8Ympn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = list(tagger.info().labels.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTmhM7KdZAa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels.remove('O')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4kYLQv0ZFfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZMnMSdUU66f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "92e4a5f0-ff63-4d92-94df-4bd97a5000e1"
      },
      "source": [
        "print(bio_classification_report(y_test, y_pred))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "        B-DATE       0.92      0.86      0.89       375\n",
            "        I-DATE       0.94      0.94      0.94       747\n",
            "       B-EMAIL       1.00      1.00      1.00         5\n",
            "       I-EMAIL       1.00      1.00      1.00        28\n",
            "         B-LAW       0.71      0.56      0.62        43\n",
            "         I-LAW       0.74      0.70      0.72       154\n",
            "         B-LEN       0.96      0.93      0.95        29\n",
            "         I-LEN       0.98      0.94      0.96        69\n",
            "    B-LOCATION       0.88      0.77      0.82       864\n",
            "    I-LOCATION       0.86      0.73      0.79       852\n",
            "       B-MONEY       0.98      0.85      0.91       105\n",
            "       I-MONEY       0.96      0.95      0.95       239\n",
            "B-ORGANIZATION       0.90      0.78      0.84      1166\n",
            "I-ORGANIZATION       0.84      0.77      0.81      1338\n",
            "     B-PERCENT       1.00      0.97      0.99        34\n",
            "     I-PERCENT       1.00      0.96      0.98        51\n",
            "      B-PERSON       0.96      0.82      0.88       676\n",
            "      I-PERSON       0.94      0.92      0.93      2424\n",
            "       B-PHONE       1.00      0.72      0.84        29\n",
            "       I-PHONE       0.96      0.92      0.94        78\n",
            "        B-TIME       0.87      0.73      0.79       172\n",
            "        I-TIME       0.94      0.83      0.88       336\n",
            "         B-URL       0.89      1.00      0.94        24\n",
            "         I-URL       0.96      1.00      0.98       371\n",
            "         B-ZIP       1.00      1.00      1.00         4\n",
            "\n",
            "     micro avg       0.91      0.84      0.87     10213\n",
            "     macro avg       0.93      0.87      0.89     10213\n",
            "  weighted avg       0.91      0.84      0.87     10213\n",
            "   samples avg       0.17      0.17      0.17     10213\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dzMQZcnaPsl",
        "colab_type": "text"
      },
      "source": [
        "## Train Full"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5X8d6ZYZ1p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "97764163-52a2-4950-f3ca-709f446222ed"
      },
      "source": [
        "%%time\n",
        "trainer_full = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_data, y_data):\n",
        "    try:\n",
        "      trainer_full.append(xseq, yseq)\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.93 s, sys: 40 ms, total: 2.97 s\n",
            "Wall time: 2.97 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsN9cjfGaAUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer_full.set_params({\n",
        "    'c1': 0.1,   # coefficient for L1 penalty\n",
        "    'c2': 0.1,  # coefficient for L2 penalty\n",
        "    'max_iterations': 500,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zUFBS30aHRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "10336338-421d-4d89-8754-03db277ee015"
      },
      "source": [
        "%%time\n",
        "trainer_full.train('thai-ner-1-4.crfsuite')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11min 48s, sys: 494 ms, total: 11min 49s\n",
            "Wall time: 11min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}